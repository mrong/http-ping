#!/usr/bin/env python3

import argparse
import signal
import socket
import subprocess
import time
from http.client import responses
from urllib.parse import urlparse


class Ping:
    def __init__(self, url, timeout, additional_curl_options, max_ip_length):
        self.url = url
        self.parsed_url = urlparse(url)
        self.timeout = timeout
        self.additional_curl_options = additional_curl_options

        self.successful_requests = 0
        self.failed_requests = 0
        self.total_time = 0
        self.request_no = 0

        max_description_length = 0

        for http_status in enumerate(responses):
            length = len(responses[http_status[1]])

            if length > max_description_length:
                max_description_length = length

        self.table_columns = [
            ("request_no", 3, "right"),
            ("ip", max(2, max_ip_length), "left"),
            ("status", 6, "right"),
            ("time", 5, "right"),
            ("description", max(11, max_description_length), "left"),
        ]

        row_length = self.print_table_row({
            "request_no": "#",
            "ip": "IP",
            "status": "Status",
            "time": "Time",
            "description": "Description",
        })

        print("".ljust(row_length, "-"))

    def show_stats(self):
        total_requests = self.successful_requests + self.failed_requests
        average_time = self.total_time / total_requests
        successful_requests_percentage = self.successful_requests / total_requests * 100
        failed_requests_percentage = self.failed_requests / total_requests * 100

        print("")
        print("-- Statistics ---")
        print("{} requests - {} successful ({}%), {} failed ({}%)".format(total_requests, self.successful_requests, successful_requests_percentage, self.failed_requests, failed_requests_percentage))
        print("Average time: {} seconds".format(round(average_time, 2)))

    def print_table_row(self, values):
        cells = []

        for key, length, align in self.table_columns:
            value = values[key]
            string_value = str(value)

            if align == "right":
                string_value = string_value.rjust(length)
            else:
                string_value = string_value.ljust(length)

            cells.append(string_value)

        string = "   ".join(cells)

        print(string.rstrip())

        return len(string)

    def do_request(self, ip=None):
        self.request_no += 1

        curl_options = [
            "-w", "%{http_code} %{time_total} %{remote_ip}",
            "-o", "/dev/null",
            "-s"
        ]

        if self.timeout:
            curl_options.append("--max-time")
            curl_options.append(self.timeout)

        if ip:
            host, port = self.parsed_url.netloc.split(":") + [None]

            if port is None:
                scheme = self.parsed_url.scheme

                if scheme == "http":
                    port = 80
                elif scheme == "https":
                    port = 443

            curl_options.append("--resolve")
            curl_options.append("{}:{}:{}".format(host, port, ip))

        if self.additional_curl_options:
            curl_options += self.additional_curl_options

        curl_command = ["curl"] + curl_options + [self.url]

        start_time = time.time()

        process = subprocess.run(curl_command, stdout=subprocess.PIPE)

        curl_output = process.stdout.decode("utf-8").split()

        if len(curl_output) == 3:
            http_code, request_time, used_ip = curl_output

            http_code = int(http_code)
            request_time = float(request_time)

            if http_code in responses:
                description = responses[http_code]
            else:
                description = "Unknown response"
        else:
            http_code = 0
            request_time = time.time() - start_time
            used_ip = ""
            description = "Curl failed ({})".format(process.returncode)

        self.total_time += request_time

        if 100 <= http_code <= 399:
            self.successful_requests += 1
        else:
            self.failed_requests += 1

        self.print_table_row({
            "request_no": self.request_no,
            "ip": used_ip,
            "status": http_code,
            "time": round(request_time, 2),
            "description": description,
        })


def dns_lookup(host, v4, v6):
    all_address_info = []

    if v4:
        try:
            all_address_info += socket.getaddrinfo(host, None, socket.AF_INET)
        except socket.gaierror:
            pass

    if v6:
        try:
            all_address_info += socket.getaddrinfo(host, None, socket.AF_INET6)
        except socket.gaierror:
            pass

    all_ip_addresses = set()

    for entry in all_address_info:
        all_ip_addresses.add(entry[4][0])

    return all_ip_addresses


def main():
    argument_parser = argparse.ArgumentParser(description="Request the given URL in a loop")

    argument_parser.add_argument("--all-ips", "-a", action="store_true", help="Request the given URL from all IP addresses (IPv4 and IPv6) behind the domain")
    argument_parser.add_argument("--all-ipv4", "-4", action="store_true", help="Request the given URL from all IPv4 addresses behind the domain")
    argument_parser.add_argument("--all-ipv6", "-6", action="store_true", help="Request the given URL from all IPv6 addresses behind the domain")
    argument_parser.add_argument("--iterations", "-i", help="Check the URL the given times (default: no limit)")
    argument_parser.add_argument("--sleep", "-s", help="Sleep the given time (default: 1 second)", default=1)
    argument_parser.add_argument("--timeout", "-t", help="Timeout for a single request (default: none)")

    argument_parser.add_argument("url", help="The URL to request")
    argument_parser.add_argument("curl_options", nargs=argparse.REMAINDER, help="Additional options to pass to curl")

    arguments = argument_parser.parse_args()

    max_iterations = arguments.iterations
    sleep = arguments.sleep
    url = arguments.url

    use_all_ips = False
    lookup_ipv4 = False
    lookup_ipv6 = False

    if arguments.all_ips or arguments.all_ipv4:
        lookup_ipv4 = True
        use_all_ips = True

    if arguments.all_ips or arguments.all_ipv6:
        lookup_ipv6 = True
        use_all_ips = True

    if lookup_ipv4 is False and lookup_ipv6 is False:
        lookup_ipv4 = True
        lookup_ipv6 = True

    ips = dns_lookup(urlparse(url).netloc.split(":")[0], lookup_ipv4, lookup_ipv6)

    iteration = 0
    max_ip_length = 0

    for ip in ips:
        length = len(ip)

        if length > max_ip_length:
            max_ip_length = length

    if max_iterations:
        print("Pinging {} {} times".format(url, max_iterations))
    else:
        print("Pinging {}".format(url))

    print("")

    ping = Ping(url=url, timeout=arguments.timeout, additional_curl_options=arguments.curl_options, max_ip_length=max_ip_length)

    signal.signal(signal.SIGINT, lambda signal_no, frame: (ping.show_stats(), exit(0)))

    while True:
        iteration += 1

        if use_all_ips:
            if not ips:
                print("No IPs found")
                exit(1)

            for ip in ips:
                ping.do_request(ip)
        else:
            ping.do_request(None)

        if max_iterations and iteration >= int(max_iterations):
            ping.show_stats()
            break

        time.sleep(float(sleep))


main()
